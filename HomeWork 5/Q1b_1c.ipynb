{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "fISsSnP6fXhN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Problem 1b\n",
        "\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv1D,Conv2D,Conv3D, MaxPooling2D\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "\n",
        "(x_train, x_train_label_int), (x_test, x_test_label_int) = mnist.load_data()\n",
        "\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "#x_train/=255\n",
        "\n",
        "\n",
        "x_test = x_test.astype('float32')\n",
        "x_test=255-x_test\n",
        "\n",
        "#only if required if comparing categorial entropy is the loss function\n",
        "x_train_label = keras.utils.to_categorical(x_train_label_int, num_classes=10)\n",
        "x_test_label=keras.utils.to_categorical(x_test_label_int, num_classes=10)\n",
        "\n",
        "x_train =x_train.reshape(x_train.shape[0],28,28,1);\n",
        "x_test =x_test.reshape(x_test.shape[0],28,28,1);\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(6,(5,5), padding='same', activation='relu',kernel_initializer='glorot_normal', bias_initializer='glorot_normal', use_bias=True,input_shape=(28,28,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
        "model.add(Conv2D(16, (5,5), strides=(1, 1), padding='valid',activation='relu',kernel_initializer='glorot_normal', bias_initializer='glorot_normal', use_bias=True))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(120, activation='relu',kernel_initializer='glorot_normal', bias_initializer='glorot_normal', use_bias=True))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Dense(84, activation='relu',kernel_initializer='glorot_normal', bias_initializer='glorot_normal', use_bias=True))\n",
        "model.add(Dense(10, activation='softmax',kernel_initializer='glorot_normal', bias_initializer='glorot_normal', use_bias=True))\n",
        "#model.summary()\n",
        "\n",
        "#keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False) \n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='Adam' ,metrics=['accuracy'])\n",
        "        \n",
        "history= model.fit(x=x_train, y=x_train_label, batch_size=100,validation_data=(x_test, x_test_label), epochs=100, verbose=1,  shuffle=True)\n",
        "          \n",
        "predicted_labels=model.predict(x_test)  \n",
        "\n",
        "score = model.evaluate(x_train, x_train_label) \n",
        "print(score)\n",
        "\n",
        "score = model.evaluate(x_test, x_test_label)         \n",
        "          \n",
        "print(score)          \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uAeyu_lOgXex",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv1D,Conv2D,Conv3D, MaxPooling2D\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "\n",
        "(x_train, x_train_label_int), (x_test, x_test_label_int) = mnist.load_data()\n",
        "\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "#x_train/=255\n",
        "\n",
        "\n",
        "x_test = x_test.astype('float32')\n",
        "x_test=255-x_test\n",
        "\n",
        "#only if required if comparing categorial entropy is the loss function\n",
        "x_train_label = keras.utils.to_categorical(x_train_label_int, num_classes=10)\n",
        "x_test_label=keras.utils.to_categorical(x_test_label_int, num_classes=10)\n",
        "\n",
        "x_train =x_train.reshape(x_train.shape[0],28,28,1);\n",
        "x_test =x_test.reshape(x_test.shape[0],28,28,1);\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(6,(5,5), padding='same', activation='relu',kernel_initializer='RandomUniform', bias_initializer='RandomUniform', use_bias=True,input_shape=(28,28,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
        "model.add(Conv2D(16, (5,5), strides=(1, 1), padding='valid',activation='relu',kernel_initializer='RandomUniform', bias_initializer='RandomUniform', use_bias=True))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(120, activation='relu',kernel_initializer='RandomUniform', bias_initializer='RandomUniform', use_bias=True))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Dense(84, activation='relu',kernel_initializer='RandomUniform', bias_initializer='RandomUniform', use_bias=True))\n",
        "model.add(Dense(10, activation='softmax',kernel_initializer='RandomUniform', bias_initializer='RandomUniform', use_bias=True))\n",
        "#model.summary()\n",
        "\n",
        "#keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False) \n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='Adam' ,metrics=['accuracy'])\n",
        "        \n",
        "history= model.fit(x=x_train, y=x_train_label, batch_size=100, epochs=100, verbose=1,  shuffle=True)\n",
        "          #,validation_data=(x_test, x_test_label)\n",
        "predicted_labels=model.predict(x_test)  \n",
        "\n",
        "score = model.evaluate(x_train, x_train_label) \n",
        "print(score)\n",
        "\n",
        "score = model.evaluate(x_test, x_test_label)         \n",
        "          \n",
        "print(score)          \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u-X6TeaigcoS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv1D,Conv2D,Conv3D, MaxPooling2D\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "\n",
        "(x_train, x_train_label_int), (x_test, x_test_label_int) = mnist.load_data()\n",
        "\n",
        "print(type(x_train))\n",
        "\n",
        "image=x_train[1]\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "\n",
        "image=x_test[1]\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_train1=255-x_train\n",
        "\n",
        "x_test = x_test.astype('float32')\n",
        "x_test1=255-x_test\n",
        "\n",
        "image=x_train1[1]\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "image=x_test1[1]\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "x_train2=np.append(x_train,x_train1,axis=0)\n",
        "x_test2=np.append(x_test,x_test1,axis=0)\n",
        "\n",
        "x_train2-=np.mean(x_train2,axis=0)\n",
        "x_test2-=np.mean(x_test2,axis=0)\n",
        "\n",
        "print((x_train2.shape))\n",
        "\n",
        "\n",
        "#only if required if comparing categorial entropy is the loss function\n",
        "x_train_label = keras.utils.to_categorical(x_train_label_int, num_classes=10)\n",
        "x_test_label=keras.utils.to_categorical(x_test_label_int, num_classes=10)\n",
        "\n",
        "x_train_label2=np.append(x_train_label,x_train_label,axis=0)\n",
        "x_test_label2=np.append(x_test_label,x_test_label,axis=0)\n",
        "\n",
        "\n",
        "x_train2 =x_train2.reshape(x_train2.shape[0],28,28,1);\n",
        "x_test2 =x_test2.reshape(x_test2.shape[0],28,28,1);\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(6,(5,5), padding='same', activation='relu',kernel_initializer='RandomUniform', bias_initializer='RandomUniform', use_bias=True,input_shape=(28,28,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
        "model.add(Conv2D(16, (5,5), strides=(1, 1), padding='valid',activation='relu',kernel_initializer='RandomUniform', bias_initializer='RandomUniform', use_bias=True))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(120, activation='relu',kernel_initializer='RandomUniform', bias_initializer='RandomUniform', use_bias=True))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Dense(84, activation='relu',kernel_initializer='RandomUniform', bias_initializer='RandomUniform', use_bias=True))\n",
        "model.add(Dense(10, activation='softmax',kernel_initializer='RandomUniform', bias_initializer='RandomUniform', use_bias=True))\n",
        "model.summary()\n",
        "          \n",
        "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
        "        \n",
        "history= model.fit(x=x_train2, y=x_train_label2, batch_size=100, epochs=100, verbose=1,  shuffle=True)\n",
        "          \n",
        "predicted_labels=model.predict(x_test2)  \n",
        "\n",
        "score = model.evaluate(x_train2, x_train_label2) \n",
        "print ('Training Loss and accuracy')\n",
        "print(score)\n",
        "\n",
        "\n",
        "score = model.evaluate(x_test2, x_test_label2)         \n",
        "print ('Testing Loss and accuracy')\n",
        "print(score)          \n",
        "\n",
        "fig = plt.figure()\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(history.history['acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "fig\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}